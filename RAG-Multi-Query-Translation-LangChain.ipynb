{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "RAG - Multi-Query Query translation\n",
    "\n",
    "Besides using the LangChain Chain/Pipeline as illustrated in the LangChain Rag tutorial below, \n",
    "this program also creates a step_to_step_query (question) function that executes within the same logic \n",
    "but without the abstract of Chain/Pipeline. it helps me to understand the processes \n",
    "and also be able to improve the prompt or question preparation better. \n",
    "Of course, langSmith is a great tool as well\n",
    "\n",
    "Please review the RAG tutorial from Langchain in details (part 5 - multi-query query translation)\n",
    "https://www.youtube.com/watch?v=JChPi0CRnDY\n",
    "\n",
    "'''\n",
    "#RAG-- Common Rag\n",
    "# Query Translation:   Multi-Query, Fusion and Decompsoition \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#if (GCP_PROJECT_ID == None): print (\"Not set\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'false'  #true for trace\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG - Multi-Query-Translation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG-- Common Rag\n",
    "# Query Translation:   Multi-Query, Fusion and Decompsoition \n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "\n",
    "#Using CharaterTextSplitter may have better result than RecursiveCharacterTextSplitter\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)\n",
    "text_splitter = CharacterTextSplitter()\n",
    "#Chunk size has no effects on CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Example: Document retriving from Web ####\n",
    "'''\n",
    "# Load Documents from Web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "doc = loader.load()\n",
    "docs = text_splitter.split_documents(doc)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG-- Common Rag\n",
    "# Query Translation:   Multi-Query, Fusion and Decompsoition \n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "def extract_pdf_text(file_path):\n",
    "    pdf_file = PdfReader(file_path)\n",
    "    text_data = ''\n",
    "    for pg in pdf_file.pages:\n",
    "        text_data += pg.extract_text()\n",
    "    return text_data\n",
    "resume_name = \".\\\\docs\\\\samcyangResume_Gen123.pdf\"\n",
    "pdf_text = extract_pdf_text(resume_name)\n",
    "pdf_texts = text_splitter.split_text(pdf_text)\n",
    "split_docs = text_splitter.create_documents(pdf_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving\n",
    "# RAG-- Common Rag\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=split_docs, \n",
    "                                    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4}, max_tokens_limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, Multi-Query or Query-Translation\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "question = \"List all the companies Sam have worked for, please also list the year he worked for those companies\"\n",
    "# Multi Query: Different Perspectives\n",
    "#question = \"Please provide summary of Sam work experience\"\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate 5\n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines.  Original question: {question}\"\"\"\n",
    "'''\n",
    "template = \"\"\"A resume contains 1. the name, the phone number and \n",
    "the address of a person, 2.  the education or attending Schools and years \n",
    "of graduation.  3. the companies a person worked for with the job titles, \n",
    "starting and ending dates, and responsibilities of that person.  4. the \n",
    "awards or social networking information of this person. Original question: {question}\"\"\"\n",
    "'''\n",
    "\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(temperature=0) \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "#question = \"Which Universities Sam have attended to?\"\n",
    "# Retrieve\n",
    "# with set_debug and set_verbose, you can see the intermediated questions generated from original question.\n",
    "\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "#set_debug(True)\n",
    "#set_verbose(True)\n",
    "\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "#docs = retrieval_chain.invoke({\"question\":question})\n",
    "#len(docs)\n",
    "\n",
    "#set_debug(False)\n",
    "#set_verbose(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "'''\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "'''\n",
    "\n",
    "template =  \"\"\"Answer the question based only on the following context \n",
    "with assumptions that A resume contains 1. the name, the phone number and \n",
    "the address of a person, 2.  the education or attending Schools and years \n",
    "of graduation.  3. the companies a person worked for with the job titles, \n",
    "starting and ending dates, and responsibilities of that person.  4. the \n",
    "awards or social networking information of this person.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Without using the Chain/Pipeline but same processes\n",
    "'''\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(temperature=0) \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "\n",
    "and\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "'''\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.load import dumps, loads\n",
    "from PyPDF2 import PdfReader\n",
    "#Using CharaterTextSplitter maybe have better results than RecursiveCharacterTextSplitter\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)\n",
    "text_splitter = CharacterTextSplitter()\n",
    "#keep the default separator ('\\n\\n') is better than separator=\"\\n\"\n",
    "\n",
    "def extract_pdf_text(file_path):\n",
    "    pdf_file = PdfReader(file_path)\n",
    "    text_data = ''\n",
    "    for pg in pdf_file.pages:\n",
    "        text_data += pg.extract_text()\n",
    "    return text_data\n",
    "\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "\n",
    "def step_by_step_query(user_question, resume):\n",
    "    from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "    #question = \"List all the companies Sam have worked for, please also list the year he worked for those companies\"\n",
    "# Multi Query: Different Perspectives\n",
    "    question = user_question\n",
    "    pdf_text = extract_pdf_text(resume)\n",
    "    pdf_texts = text_splitter.split_text(pdf_text)\n",
    "    split_docs = text_splitter.create_documents(pdf_texts)\n",
    "    ''' Don't use OpenAIEmbeddings\n",
    "    client = OpenAI()\n",
    "    embedding_repsonse = client.embeddings.create(input=sentences, \n",
    "                                      model=\"text-embedding-3-large\")\n",
    "     '''\n",
    "    \n",
    "    vectorstore = Chroma.from_documents(documents=split_docs, \n",
    "                                    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4}, max_tokens_limit=10000)\n",
    "    \n",
    "    template = \"\"\"You are an AI language model assistant. Your task is to generate 5 different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search.  Provide these alternative questions separated by newlines.  Original question: {question}\"\"\"\n",
    "\n",
    "    prompt_perspectives_output =  prompt_perspectives.invoke(question)\n",
    "    #print(\"Output after prompt_perspectives:\", prompt_perspectives_output)\n",
    "\n",
    "    chat_openai_output = ChatOpenAI(temperature=0)(prompt_perspectives_output)\n",
    "    ##print(\"Output after ChatOpenAI:\", chat_openai_output)\n",
    "    #output_parser = CommaSeparatedListOutputParser()\n",
    "    parser_output = StrOutputParser().invoke(chat_openai_output)\n",
    "    #print(\"output after StrOutputParser:\", parser_output)\n",
    "    #str_output_parser_output = output_parser(chat_openai_output)\n",
    "    #print(\"Output after StrOutputParser:\", str_output_parser_output)\n",
    "\n",
    "    generate_queries= (lambda x: x.split(\"\\n\"))(parser_output)\n",
    "\n",
    "    print (generate_queries)\n",
    "\n",
    "    #retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "    # and \n",
    "    #docs = retrieval_chain.invoke({\"question\":question})\n",
    "\n",
    "    retriever_output = retriever.map().invoke(generate_queries)\n",
    "\n",
    "    #print(\"output after retriever map()\", retriever_output)\n",
    "\n",
    "    get_union_doc_output = get_unique_union(retriever_output)\n",
    "\n",
    "    #print(\"output after get_unique_union\", get_union_doc_output)\n",
    "\n",
    "    #docs = retrieval_chain.invoke({\"question\":question})\n",
    "    #docs = get_union_doc_output\n",
    "\n",
    "    #print(\"output after retriever_chain\", docs)\n",
    "\n",
    "    template =  \"\"\"Answer the question based only on the following context with assumptions that A resume contains 1. the name, the phone number and the address of a person, 2.  the education or attending Schools and years \n",
    "of graduation.  3. the companies a person worked for with the job titles, starting and ending dates, and responsibilities of that person.  4. the awards or social networking information of this person.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "\n",
    "    #docsf = retriever.map().invoke({\"question\":question})\n",
    "\n",
    "    #print(\"output after retriever_chain again.. \", docsf)\n",
    "    prompt_outputf =  prompt.invoke({\"context\": get_union_doc_output, \"question\":question})\n",
    "    #print(\"output from prompt again\", prompt_outputf)\n",
    "    llm_output = llm(prompt_outputf)\n",
    "    #print(\"Output from llm again\", llm_output)\n",
    "    print (llm_output.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Can you provide a list of companies where Sam has been employed along with the corresponding years of his employment?', '2. Which companies has Sam worked for, and can you include the years he worked at each company?', \"3. I'm interested in knowing the companies that Sam has worked for and the specific years he was employed at each company. Can you provide this information?\", '4. Could you list the companies where Sam has gained work experience, including the years he spent at each company?', '5. Please provide a comprehensive list of the companies that Sam has worked for, along with the respective years of his employment at each company.']\n",
      "1. Tarana Wireless - 10/2022 - 12/2023\n",
      "2. Miso Robotics - 11/2021 - 09/2022\n",
      "3. Quasar Science - 6/2020 - 11/2021\n",
      "4. Riverbed/Xirrus Inc - 10/2012 - 9/2019\n",
      "5. JigoCity/Ecommerce - 1/2011 - 5/2012\n",
      "6. Concordware International/China Offshore Software Development - 5/2009 - 10/2010\n",
      "7. Asoka USA - 8/2007 - 8/2008\n",
      "8. Boingo Wireless - 11/2006 - 3/2007\n",
      "9. Infospace Mobile Division - 7 - 11/2006\n",
      "10. Telemac - 8/2004 - 6/2006\n"
     ]
    }
   ],
   "source": [
    "question = \"List all the companies Sam have worked for, please also list the year he worked for those companies\"\n",
    "resume='.\\samcyangResume_Gen123.pdf'\n",
    "step_by_step_query(question, resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1. What is Sam's background in hardware and software development?\", '2. Can Sam demonstrate proficiency in both hardware and software development?', '3. Has Sam worked on projects involving both hardware and software development?', '4. Is Sam skilled in both hardware and software development?', '5. Does Sam possess expertise in both hardware and software development?']\n",
      "Yes, Sam has experience in both hardware and software development.\n"
     ]
    }
   ],
   "source": [
    "question = \"Does Sam have experience in both hardware and software development\"\n",
    "resume='.\\samcyangResume_Gen123.pdf'\n",
    "step_by_step_query(question, resume)\n",
    "#using default separator in splitter is better than setting separator='\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. What is the duration of NPI experience that Sam possesses and which companies has he gained this experience in?', '2. In which companies has Sam accumulated his NPI experience over the years?', '3. How many years of NPI experience does Sam have, and where has he worked to gain this experience?', '4. Which companies has Sam worked for to acquire his NPI experience, and for how many years?', '5. Can you provide details on the duration of NPI experience Sam has and the companies where he gained this experience?']\n",
      "Sam has 15+ years of NPI experience. He gained this experience at the following companies:\n",
      "1. Tarana Wireless\n",
      "2. Quasar Science\n",
      "3. Riverbed/Xirrus Inc\n"
     ]
    }
   ],
   "source": [
    "question = \"how many years of NPI experience Sam has it and in what companies\"\n",
    "resume='.\\samcyangResume_Gen456.pdf'\n",
    "step_by_step_query(question, resume)\n",
    "#Doesn't answer the years correctly, may need to find-tune the template#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1. What is Sam's experience with AI and robotics, and can you provide details on the last company he worked for and the years he utilized his AI and robotics skills?\", \"2. Can you tell me about Sam's background in AI and robotics, including information on his most recent company and the timeframe during which he applied his expertise in this field?\", '3. Has Sam worked with AI and robotics before, and if so, could you specify the company where he gained this experience and the duration of his involvement?', \"4. I'm interested in Sam's AI and robotics experience. Could you share details about his previous company and the years he spent working with AI and robotics technologies?\", \"5. What is Sam's history with AI and robotics, and can you provide insights into the last company he was associated with and the period during which he utilized his AI and robotics knowledge?\"]\n",
      "Yes, Sam has AI and robotics experience. The last company where he used his AI and Robotics experience is Miso Robotics from 11/2021 - 09/2022.\n"
     ]
    }
   ],
   "source": [
    "# llm responses the wrong answer if you ask list all companies he uses AI and robotics,\n",
    "question = \"Does Sam have AI and robotics experience, and please list the last company and years he uses the AI and Robotics experience?\"\n",
    "resume='.\\samcyangResume_Gen456.pdf'\n",
    "step_by_step_query(question, resume)\n",
    "#The answer is not ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
